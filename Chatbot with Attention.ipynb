{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e434ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Embedding, Input\n",
    "from tensorflow.keras.layers import Concatenate, Activation, Dot\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9e4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_over_time(x):\n",
    "    assert(K.ndim(x) > 2) #checks to see if it is higher than 2 dimensions\n",
    "    #exp and over T in dimension N x T x D\n",
    "    # max of all T in each N X D\n",
    "    e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "    \n",
    "    # sum of all T in each N X D\n",
    "    s = K.sum(e, axis=1, keepdims=True)\n",
    "    return e/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827d562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 200\n",
    "LATENT_DIM = 256\n",
    "LATENT_DIM_DECODER = 256\n",
    "NUM_SAMPLES = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b16909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = keras.utils.get_file(\n",
    "    fname=\"spa-eng.zip\",\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d73f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 10000\n"
     ]
    }
   ],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "target_texts_inputs = []\n",
    "t = 0\n",
    "for line in open(text_file, encoding='utf-8'):\n",
    "    t+=1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "        \n",
    "    if '\\t' not in line:#if input and target are not seperated\n",
    "        continue\n",
    "        \n",
    "    #split    \n",
    "    input_text, translation = line.split(\"\\t\")\n",
    "    \n",
    "    target_text = translation.replace(\"\\n\", \"\") + ' <eos>'\n",
    "    target_text_input ='<sos> '+ translation.replace(\"\\n\", \"\")\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)\n",
    "print('num samples:', len(input_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c2f1c",
   "metadata": {},
   "source": [
    "# ENCODER Inputs Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b39f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input text of the encoder\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e0794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2367 unique input tokens.\n"
     ]
    }
   ],
   "source": [
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print(\"Found %s unique input tokens.\" %len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f67e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f59f6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_data.shape:  (10000, 5)\n",
      "encoder_data[0] :  [ 0  0  0  0 15]\n"
     ]
    }
   ],
   "source": [
    "#pad sequences for text in encoder\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_data.shape: \", encoder_inputs.shape)\n",
    "print(\"encoder_data[0] : \", encoder_inputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa91a0",
   "metadata": {},
   "source": [
    "# Decoder Target and Decoder Input Targets\n",
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f479dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_outputs = Tokenizer(num_words = MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
    "#translation for decoder target_texts\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "#translation for decoder input_texts\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17cd9db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6325 unique token ouputs.\n"
     ]
    }
   ],
   "source": [
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print(\"Found %s unique token ouputs.\" %len(word2idx_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb71de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_output = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "145c9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f45b792",
   "metadata": {},
   "source": [
    "# Padding decoder Inputs of translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84bdee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_data.shape:  (10000, 9)\n",
      "decoder_data[0] :  [   2 1491    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "#the decoder input test <SOS> padded which are the target also\n",
    "# this is use for teacher forcing\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target,\n",
    "                              padding='post')\n",
    "print(\"decoder_data.shape: \", decoder_inputs.shape)\n",
    "print(\"decoder_data[0] : \", decoder_inputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6668b45",
   "metadata": {},
   "source": [
    "# Target for Decoder padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed6bdeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the decoder target text ends in <EOS> which are similar to input of decoder\n",
    "# difference is that it ends with <eos> instead of the <sos> which is at start\n",
    "decoder_targets= pad_sequences(target_sequences, maxlen=max_len_target,\n",
    "                              padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7692a8",
   "metadata": {},
   "source": [
    "# Pretrained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d93b255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading word vectors...\")\n",
    "word2vec = {}\n",
    "with open(\"glove.6B.%sd.txt\" %EMBEDDING_DIM, encoding=\"utf-8\") as f:\n",
    "    \n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "\n",
    "print(\"Found %s word vectors.\" %len(word2vec)) #dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e2e1ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIlling pre traineed embeddings...\n"
     ]
    }
   ],
   "source": [
    "print(\"FIlling pre traineed embeddings...\")\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs)+1)\n",
    "embedding_matrix = np.zeros((num_words,EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b7d125",
   "metadata": {},
   "source": [
    "# Create Embedding layer with\n",
    "# Pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7be416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_words,\n",
    "    EMBEDDING_DIM,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=max_len_target,\n",
    "    #trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe3fac",
   "metadata": {},
   "source": [
    "# Encoder Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1260d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model encoder\n",
    "#input of the english inputs for the encoder\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "\n",
    "#embedding_layer is word2vec pretrained embedding\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "\n",
    "#LATENT_DIM is the hidden_neurons in the lstm\n",
    "encoder = Bidirectional(LSTM(LATENT_DIM, return_sequences=True, dropout=0.5))\n",
    "#output of 2M, M=LATENT_DIM\n",
    "\n",
    "#grab the output of multiple hidden_states becuase of return_sequence=True\n",
    "encoder_outputs = encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88080c",
   "metadata": {},
   "source": [
    "# Decoder Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25195d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input of the spanish inputs for the decoder\n",
    "# max_len_target = T\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "#new embedding layer with the dimensionality for spanish embedding\n",
    "#num_words_output = V, Embedding_dim = D represent weight matrix = (V,D)\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM) \n",
    "\n",
    "# output of the embedding is N x T x D\n",
    "# N = number of samples, T=length of sentence, D = neurons in layer\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0d251",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "494efa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reusable layers for the loop but have no value for now\n",
    "#repeat same weight Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "\n",
    "#last dimension has the output important values that are added\n",
    "#last dimension is LATENT_DIM which as we recall is M and h from\n",
    "# encoder has 2M as output\n",
    "# s(t-1) is M  for the decoder lstm so adding both 2M and M \n",
    "# which is the last dimension\n",
    "attn_concat_layer = Concatenate(axis=-1) #concatenate in the last dimension\n",
    "\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    " # perform the weighted sum of alpha[t] * h[t] to get context\n",
    "attn_dot = Dot(axes=1) #vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6eb2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that will use previous layers\n",
    "def one_step_attention(h,st_1):\n",
    "    \n",
    "    #copy s(t-1) Tx times\n",
    "    #shape = (Tx, Latent_dim_decoder)\n",
    "    st_1 = attn_repeat_layer(st_1)\n",
    "    \n",
    "    #concaternat all h(t)'s with s(t-1)\n",
    "    #shape  (Tx, Latent_dim_decoder + Latent_dim *2)\n",
    "    #sum over the axis=1 which is the sum of the columns for each row\n",
    "    x = attn_concat_layer([h, st_1])\n",
    "    \n",
    "    #neural net first layer with tanh\n",
    "    x = attn_dense1(x)\n",
    "    \n",
    "    #neural net second layer with special softmax over time\n",
    "    alphas = attn_dense2(x)\n",
    "    \n",
    "    #dot for the alphas and the hidden_states h's\n",
    "    context = attn_dot([alphas, h])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5d061",
   "metadata": {},
   "source": [
    "# After Attention\n",
    "# LSTM implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2667549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax') #softmax\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "\n",
    "#adding all vaues in the third dimension for each row and column\n",
    "context_last_word_concat_layer = Concatenate(axis=2)#teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39bf2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will be re-assigned for each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de7c186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output collection\n",
    "outputs=[]\n",
    "for t in range(max_len_target): #Ty times for the output\n",
    "    \n",
    "    #get the context using attention funciton\n",
    "    #encoder_outputs is the output of the bidirectional lstm\n",
    "    #bidirectional with return_sequence returns multiple hidden_states\n",
    "    context = one_step_attention(encoder_outputs, s)\n",
    "    \n",
    "    #allows us to get a new word embeded for teacher forcing\n",
    "    #this is a lambda layer different to a regular lambda\n",
    "    selector = Lambda(lambda x: x[:, t:t+1]) #new word\n",
    "    \n",
    "    #input the decoder_input_x which outputs the embedding of \n",
    "    #sequence which is the each word in a sentence but we pick\n",
    "    #one word at the time with the selector lambda\n",
    "    xt = selector(decoder_inputs_x)\n",
    "    \n",
    "    #combine for teacher forcing and is ready to be use as\n",
    "    # the input of the lstm in decoder\n",
    "    decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "    \n",
    "    #pass in the combine [context, last word] into the lstm\n",
    "    #one word at a time xt which is for teacher forcing\n",
    "    #with the [s, c] states\n",
    "    # get new output, s and c\n",
    "    o,s,c = decoder_lstm(decoder_lstm_input, initial_state=[s,c])\n",
    "    \n",
    "    #final dense layer to get the nexxt word prediction\n",
    "    decoder_outputs = decoder_dense(o) #softmax\n",
    "    \n",
    "    #add the output the outputs list\n",
    "    outputs.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a917233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_and_transpose(x):\n",
    "    #x is a list of lenght T, each element is a\n",
    "    # batch_size x output_vocab_size tensor (b,V)\n",
    "    x = K.stack(x) #is now  T x b x V \n",
    "    \n",
    "    #batch_size x T x V \n",
    "    # b x T x V\n",
    "    # allows to change where each dimension should be with its values\n",
    "    x = K.permute_dimensions(x, pattern=(1,0,2))\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c82f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it into a layer \n",
    "#faster for layer formation will be Permute from layers\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "#this is the last layer of the model\n",
    "outputs = stacker(outputs) # we insert the list so it can stack as a sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c957abc0",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ee223f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    #place holders for inputs start of model first layer\n",
    "    inputs=[\n",
    "        encoder_inputs_placeholder,\n",
    "        decoder_inputs_placeholder,\n",
    "        initial_s,\n",
    "        initial_c,\n",
    "    ],\n",
    "    \n",
    "    #output of the last layer of the model\n",
    "    outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c345f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss ='SparseCategoricalCrossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e2204f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - 57s 293ms/step - loss: 3.2766 - accuracy: 0.5885 - val_loss: 3.0676 - val_accuracy: 0.5573\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 31s 251ms/step - loss: 2.4893 - accuracy: 0.6334 - val_loss: 3.0098 - val_accuracy: 0.5914\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 32s 254ms/step - loss: 2.3974 - accuracy: 0.6442 - val_loss: 2.9899 - val_accuracy: 0.6028\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 2.3345 - accuracy: 0.6515 - val_loss: 2.9779 - val_accuracy: 0.5992\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 32s 254ms/step - loss: 2.2830 - accuracy: 0.6552 - val_loss: 2.9208 - val_accuracy: 0.6051\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 2.2306 - accuracy: 0.6593 - val_loss: 2.8535 - val_accuracy: 0.6137\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 32s 259ms/step - loss: 2.1710 - accuracy: 0.6662 - val_loss: 2.8152 - val_accuracy: 0.6167\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 32s 258ms/step - loss: 2.1121 - accuracy: 0.6712 - val_loss: 2.8099 - val_accuracy: 0.6179\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 32s 258ms/step - loss: 2.0600 - accuracy: 0.6753 - val_loss: 2.7721 - val_accuracy: 0.6215\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 32s 260ms/step - loss: 2.0069 - accuracy: 0.6782 - val_loss: 2.7613 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 32s 256ms/step - loss: 1.9519 - accuracy: 0.6843 - val_loss: 2.7205 - val_accuracy: 0.6234\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 1.8936 - accuracy: 0.6898 - val_loss: 2.7134 - val_accuracy: 0.6274\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 32s 256ms/step - loss: 1.8348 - accuracy: 0.6935 - val_loss: 2.6877 - val_accuracy: 0.6304\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 32s 257ms/step - loss: 1.7752 - accuracy: 0.6993 - val_loss: 2.6482 - val_accuracy: 0.6342\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 32s 258ms/step - loss: 1.7180 - accuracy: 0.7047 - val_loss: 2.6365 - val_accuracy: 0.6331\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 32s 257ms/step - loss: 1.6634 - accuracy: 0.7094 - val_loss: 2.6031 - val_accuracy: 0.6389\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 32s 258ms/step - loss: 1.6067 - accuracy: 0.7132 - val_loss: 2.5919 - val_accuracy: 0.6418\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 32s 260ms/step - loss: 1.5523 - accuracy: 0.7177 - val_loss: 2.5790 - val_accuracy: 0.6427\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 32s 257ms/step - loss: 1.4950 - accuracy: 0.7212 - val_loss: 2.5678 - val_accuracy: 0.6467\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 32s 258ms/step - loss: 1.4410 - accuracy: 0.7272 - val_loss: 2.5425 - val_accuracy: 0.6496\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 33s 260ms/step - loss: 1.3926 - accuracy: 0.7294 - val_loss: 2.5299 - val_accuracy: 0.6518\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 33s 262ms/step - loss: 1.3335 - accuracy: 0.7353 - val_loss: 2.5206 - val_accuracy: 0.6544\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 32s 260ms/step - loss: 1.2819 - accuracy: 0.7392 - val_loss: 2.5064 - val_accuracy: 0.6568\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 1.2328 - accuracy: 0.7436 - val_loss: 2.4920 - val_accuracy: 0.6624\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 32s 260ms/step - loss: 1.1793 - accuracy: 0.7492 - val_loss: 2.4874 - val_accuracy: 0.6621\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 32s 260ms/step - loss: 1.1372 - accuracy: 0.7538 - val_loss: 2.4637 - val_accuracy: 0.6646\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 33s 261ms/step - loss: 1.0939 - accuracy: 0.7572 - val_loss: 2.4531 - val_accuracy: 0.6683\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 33s 262ms/step - loss: 1.0462 - accuracy: 0.7621 - val_loss: 2.4463 - val_accuracy: 0.6674\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 33s 262ms/step - loss: 1.0038 - accuracy: 0.7664 - val_loss: 2.4488 - val_accuracy: 0.6710\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 33s 261ms/step - loss: 0.9651 - accuracy: 0.7708 - val_loss: 2.4383 - val_accuracy: 0.6684\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 33s 263ms/step - loss: 0.9295 - accuracy: 0.7761 - val_loss: 2.4343 - val_accuracy: 0.6702\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 33s 263ms/step - loss: 0.8937 - accuracy: 0.7814 - val_loss: 2.4225 - val_accuracy: 0.6750\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 33s 263ms/step - loss: 0.8549 - accuracy: 0.7867 - val_loss: 2.4308 - val_accuracy: 0.6688\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 33s 262ms/step - loss: 0.8225 - accuracy: 0.7922 - val_loss: 2.4184 - val_accuracy: 0.6772\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 33s 263ms/step - loss: 0.7943 - accuracy: 0.7961 - val_loss: 2.4194 - val_accuracy: 0.6698\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.7640 - accuracy: 0.8011 - val_loss: 2.4211 - val_accuracy: 0.6733\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.7383 - accuracy: 0.8069 - val_loss: 2.4174 - val_accuracy: 0.6751\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.7120 - accuracy: 0.8107 - val_loss: 2.4144 - val_accuracy: 0.6763\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 33s 263ms/step - loss: 0.6857 - accuracy: 0.8153 - val_loss: 2.4091 - val_accuracy: 0.6798\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.6655 - accuracy: 0.8183 - val_loss: 2.4133 - val_accuracy: 0.6766\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.6449 - accuracy: 0.8225 - val_loss: 2.4152 - val_accuracy: 0.6764\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 33s 265ms/step - loss: 0.6215 - accuracy: 0.8274 - val_loss: 2.4241 - val_accuracy: 0.6811\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.6016 - accuracy: 0.8302 - val_loss: 2.4131 - val_accuracy: 0.6808\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.5840 - accuracy: 0.8345 - val_loss: 2.4188 - val_accuracy: 0.6782\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.5674 - accuracy: 0.8356 - val_loss: 2.4170 - val_accuracy: 0.6768\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.5502 - accuracy: 0.8406 - val_loss: 2.4246 - val_accuracy: 0.6797\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 33s 267ms/step - loss: 0.5344 - accuracy: 0.8435 - val_loss: 2.4281 - val_accuracy: 0.6792\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.5208 - accuracy: 0.8471 - val_loss: 2.4275 - val_accuracy: 0.6786\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.5077 - accuracy: 0.8488 - val_loss: 2.4295 - val_accuracy: 0.6820\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.4926 - accuracy: 0.8520 - val_loss: 2.4327 - val_accuracy: 0.6802\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.4815 - accuracy: 0.8538 - val_loss: 2.4417 - val_accuracy: 0.6847\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 33s 268ms/step - loss: 0.4668 - accuracy: 0.8580 - val_loss: 2.4415 - val_accuracy: 0.6814\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 33s 267ms/step - loss: 0.4576 - accuracy: 0.8595 - val_loss: 2.4422 - val_accuracy: 0.6862\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 34s 270ms/step - loss: 0.4440 - accuracy: 0.8629 - val_loss: 2.4428 - val_accuracy: 0.6852\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 34s 269ms/step - loss: 0.4358 - accuracy: 0.8628 - val_loss: 2.4457 - val_accuracy: 0.6845\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 33s 267ms/step - loss: 0.4261 - accuracy: 0.8659 - val_loss: 2.4435 - val_accuracy: 0.6836\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.4162 - accuracy: 0.8681 - val_loss: 2.4412 - val_accuracy: 0.6811\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 33s 266ms/step - loss: 0.4094 - accuracy: 0.8681 - val_loss: 2.4428 - val_accuracy: 0.6841\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 33s 267ms/step - loss: 0.4038 - accuracy: 0.8691 - val_loss: 2.4556 - val_accuracy: 0.6849\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 34s 269ms/step - loss: 0.3928 - accuracy: 0.8720 - val_loss: 2.4551 - val_accuracy: 0.6863\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 33s 268ms/step - loss: 0.3844 - accuracy: 0.8727 - val_loss: 2.4535 - val_accuracy: 0.6860\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 34s 269ms/step - loss: 0.3721 - accuracy: 0.8750 - val_loss: 2.4718 - val_accuracy: 0.6889\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 33s 268ms/step - loss: 0.3701 - accuracy: 0.8754 - val_loss: 2.4705 - val_accuracy: 0.6849\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 33s 268ms/step - loss: 0.3626 - accuracy: 0.8771 - val_loss: 2.4716 - val_accuracy: 0.6868\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 34s 271ms/step - loss: 0.3550 - accuracy: 0.8794 - val_loss: 2.4818 - val_accuracy: 0.6836\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 34s 270ms/step - loss: 0.3475 - accuracy: 0.8806 - val_loss: 2.4834 - val_accuracy: 0.6874\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 34s 269ms/step - loss: 0.3468 - accuracy: 0.8798 - val_loss: 2.4818 - val_accuracy: 0.6855\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 34s 271ms/step - loss: 0.3366 - accuracy: 0.8820 - val_loss: 2.4969 - val_accuracy: 0.6876\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 34s 271ms/step - loss: 0.3332 - accuracy: 0.8826 - val_loss: 2.4739 - val_accuracy: 0.6872\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 34s 272ms/step - loss: 0.3291 - accuracy: 0.8840 - val_loss: 2.5030 - val_accuracy: 0.6884\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 34s 274ms/step - loss: 0.3196 - accuracy: 0.8862 - val_loss: 2.4921 - val_accuracy: 0.6871\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 34s 272ms/step - loss: 0.3173 - accuracy: 0.8868 - val_loss: 2.5044 - val_accuracy: 0.6863\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 34s 270ms/step - loss: 0.3118 - accuracy: 0.8872 - val_loss: 2.5098 - val_accuracy: 0.6856\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 34s 271ms/step - loss: 0.3075 - accuracy: 0.8892 - val_loss: 2.5103 - val_accuracy: 0.6869\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 34s 271ms/step - loss: 0.3055 - accuracy: 0.8876 - val_loss: 2.5166 - val_accuracy: 0.6851\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 35s 280ms/step - loss: 0.3009 - accuracy: 0.8899 - val_loss: 2.5078 - val_accuracy: 0.6891\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 35s 276ms/step - loss: 0.2946 - accuracy: 0.8902 - val_loss: 2.5162 - val_accuracy: 0.6851\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 34s 276ms/step - loss: 0.2923 - accuracy: 0.8907 - val_loss: 2.5180 - val_accuracy: 0.6872\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 35s 276ms/step - loss: 0.2881 - accuracy: 0.8917 - val_loss: 2.5095 - val_accuracy: 0.6861\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 34s 276ms/step - loss: 0.2847 - accuracy: 0.8934 - val_loss: 2.5375 - val_accuracy: 0.6897\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 35s 277ms/step - loss: 0.2826 - accuracy: 0.8938 - val_loss: 2.5289 - val_accuracy: 0.6884\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 35s 278ms/step - loss: 0.2777 - accuracy: 0.8944 - val_loss: 2.5448 - val_accuracy: 0.6829\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 35s 278ms/step - loss: 0.2731 - accuracy: 0.8949 - val_loss: 2.5457 - val_accuracy: 0.6888\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 35s 276ms/step - loss: 0.2699 - accuracy: 0.8958 - val_loss: 2.5429 - val_accuracy: 0.6873\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 35s 278ms/step - loss: 0.2700 - accuracy: 0.8952 - val_loss: 2.5586 - val_accuracy: 0.6855\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 35s 277ms/step - loss: 0.2663 - accuracy: 0.8955 - val_loss: 2.5681 - val_accuracy: 0.6859\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 35s 278ms/step - loss: 0.2633 - accuracy: 0.8975 - val_loss: 2.5573 - val_accuracy: 0.6889\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 35s 278ms/step - loss: 0.2605 - accuracy: 0.8970 - val_loss: 2.5492 - val_accuracy: 0.6898\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 35s 279ms/step - loss: 0.2566 - accuracy: 0.8976 - val_loss: 2.5709 - val_accuracy: 0.6896\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 35s 281ms/step - loss: 0.2558 - accuracy: 0.8980 - val_loss: 2.5764 - val_accuracy: 0.6862\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 35s 283ms/step - loss: 0.2547 - accuracy: 0.8979 - val_loss: 2.5799 - val_accuracy: 0.6859\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 35s 281ms/step - loss: 0.2537 - accuracy: 0.8981 - val_loss: 2.5754 - val_accuracy: 0.6851\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 35s 281ms/step - loss: 0.2485 - accuracy: 0.8988 - val_loss: 2.6088 - val_accuracy: 0.6872\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 35s 281ms/step - loss: 0.2463 - accuracy: 0.8996 - val_loss: 2.5889 - val_accuracy: 0.6877\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 35s 281ms/step - loss: 0.2446 - accuracy: 0.9008 - val_loss: 2.6003 - val_accuracy: 0.6858\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 35s 282ms/step - loss: 0.2418 - accuracy: 0.9005 - val_loss: 2.5988 - val_accuracy: 0.6881\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.2409 - accuracy: 0.9005 - val_loss: 2.5893 - val_accuracy: 0.6875\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.2404 - accuracy: 0.9008 - val_loss: 2.5997 - val_accuracy: 0.6866\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.2365 - accuracy: 0.9012 - val_loss: 2.5912 - val_accuracy: 0.6846\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 36s 286ms/step - loss: 0.2343 - accuracy: 0.9009 - val_loss: 2.6032 - val_accuracy: 0.6853\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.2335 - accuracy: 0.9018 - val_loss: 2.6019 - val_accuracy: 0.6897\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 36s 285ms/step - loss: 0.2307 - accuracy: 0.9022 - val_loss: 2.6129 - val_accuracy: 0.6891\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.2291 - accuracy: 0.9020 - val_loss: 2.6064 - val_accuracy: 0.6884\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.2284 - accuracy: 0.9031 - val_loss: 2.6185 - val_accuracy: 0.6897\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.2273 - accuracy: 0.9016 - val_loss: 2.6089 - val_accuracy: 0.6891\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 36s 287ms/step - loss: 0.2283 - accuracy: 0.9022 - val_loss: 2.6146 - val_accuracy: 0.6876\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.2228 - accuracy: 0.9046 - val_loss: 2.6231 - val_accuracy: 0.6873\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.2246 - accuracy: 0.9037 - val_loss: 2.6239 - val_accuracy: 0.6897\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 36s 290ms/step - loss: 0.2217 - accuracy: 0.9046 - val_loss: 2.6219 - val_accuracy: 0.6906\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 36s 290ms/step - loss: 0.2215 - accuracy: 0.9039 - val_loss: 2.6255 - val_accuracy: 0.6888\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 36s 290ms/step - loss: 0.2205 - accuracy: 0.9029 - val_loss: 2.6275 - val_accuracy: 0.6872\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.2184 - accuracy: 0.9041 - val_loss: 2.6308 - val_accuracy: 0.6877\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.2186 - accuracy: 0.9037 - val_loss: 2.6325 - val_accuracy: 0.6891\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 37s 295ms/step - loss: 0.2166 - accuracy: 0.9049 - val_loss: 2.6476 - val_accuracy: 0.6885\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.2148 - accuracy: 0.9042 - val_loss: 2.6395 - val_accuracy: 0.6873\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.2124 - accuracy: 0.9058 - val_loss: 2.6532 - val_accuracy: 0.6914\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 36s 290ms/step - loss: 0.2118 - accuracy: 0.9047 - val_loss: 2.6639 - val_accuracy: 0.6873\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.2116 - accuracy: 0.9052 - val_loss: 2.6441 - val_accuracy: 0.6873\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.2099 - accuracy: 0.9059 - val_loss: 2.6497 - val_accuracy: 0.6841\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.2078 - accuracy: 0.9067 - val_loss: 2.6591 - val_accuracy: 0.6841\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 37s 294ms/step - loss: 0.2102 - accuracy: 0.9048 - val_loss: 2.6565 - val_accuracy: 0.6849\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 37s 294ms/step - loss: 0.2085 - accuracy: 0.9056 - val_loss: 2.6579 - val_accuracy: 0.6847\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.2079 - accuracy: 0.9062 - val_loss: 2.6602 - val_accuracy: 0.6843\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 37s 294ms/step - loss: 0.2072 - accuracy: 0.9051 - val_loss: 2.6688 - val_accuracy: 0.6855\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 37s 295ms/step - loss: 0.2060 - accuracy: 0.9050 - val_loss: 2.6674 - val_accuracy: 0.6907\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 37s 293ms/step - loss: 0.2027 - accuracy: 0.9062 - val_loss: 2.6809 - val_accuracy: 0.6853\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 37s 297ms/step - loss: 0.2028 - accuracy: 0.9075 - val_loss: 2.6802 - val_accuracy: 0.6898\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 37s 295ms/step - loss: 0.2028 - accuracy: 0.9075 - val_loss: 2.6901 - val_accuracy: 0.6894\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 37s 297ms/step - loss: 0.2041 - accuracy: 0.9055 - val_loss: 2.6720 - val_accuracy: 0.6898\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 37s 297ms/step - loss: 0.2034 - accuracy: 0.9065 - val_loss: 2.6797 - val_accuracy: 0.6882\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 37s 297ms/step - loss: 0.2022 - accuracy: 0.9060 - val_loss: 2.7103 - val_accuracy: 0.6883\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 37s 298ms/step - loss: 0.2005 - accuracy: 0.9063 - val_loss: 2.6946 - val_accuracy: 0.6881\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 37s 298ms/step - loss: 0.1994 - accuracy: 0.9072 - val_loss: 2.6939 - val_accuracy: 0.6898\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 37s 299ms/step - loss: 0.1978 - accuracy: 0.9081 - val_loss: 2.6792 - val_accuracy: 0.6864\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 37s 300ms/step - loss: 0.1974 - accuracy: 0.9080 - val_loss: 2.6982 - val_accuracy: 0.6899\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 37s 300ms/step - loss: 0.1981 - accuracy: 0.9080 - val_loss: 2.6789 - val_accuracy: 0.6914\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 38s 300ms/step - loss: 0.1993 - accuracy: 0.9063 - val_loss: 2.6934 - val_accuracy: 0.6890\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 37s 300ms/step - loss: 0.1963 - accuracy: 0.9075 - val_loss: 2.6909 - val_accuracy: 0.6881\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 38s 301ms/step - loss: 0.1977 - accuracy: 0.9074 - val_loss: 2.6946 - val_accuracy: 0.6927\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 38s 302ms/step - loss: 0.1960 - accuracy: 0.9065 - val_loss: 2.6951 - val_accuracy: 0.6876\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 38s 305ms/step - loss: 0.1943 - accuracy: 0.9072 - val_loss: 2.7011 - val_accuracy: 0.6886\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 38s 302ms/step - loss: 0.1955 - accuracy: 0.9080 - val_loss: 2.6975 - val_accuracy: 0.6880\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 0.1949 - accuracy: 0.9072 - val_loss: 2.7098 - val_accuracy: 0.6886\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 0.1943 - accuracy: 0.9059 - val_loss: 2.7145 - val_accuracy: 0.6890\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 0.1923 - accuracy: 0.9076 - val_loss: 2.6991 - val_accuracy: 0.6855\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 38s 305ms/step - loss: 0.1926 - accuracy: 0.9086 - val_loss: 2.7090 - val_accuracy: 0.6857\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 0.1919 - accuracy: 0.9076 - val_loss: 2.7212 - val_accuracy: 0.6903\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 38s 305ms/step - loss: 0.1929 - accuracy: 0.9065 - val_loss: 2.7113 - val_accuracy: 0.6865\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - 38s 306ms/step - loss: 0.1925 - accuracy: 0.9067 - val_loss: 2.7280 - val_accuracy: 0.6855\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 38s 307ms/step - loss: 0.1908 - accuracy: 0.9088 - val_loss: 2.7377 - val_accuracy: 0.6900\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 38s 308ms/step - loss: 0.1895 - accuracy: 0.9085 - val_loss: 2.7318 - val_accuracy: 0.6848\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 38s 306ms/step - loss: 0.1896 - accuracy: 0.9079 - val_loss: 2.7318 - val_accuracy: 0.6881\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 39s 309ms/step - loss: 0.1919 - accuracy: 0.9074 - val_loss: 2.7200 - val_accuracy: 0.6883\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 40s 321ms/step - loss: 0.1900 - accuracy: 0.9084 - val_loss: 2.7392 - val_accuracy: 0.6898\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 41s 326ms/step - loss: 0.1892 - accuracy: 0.9077 - val_loss: 2.7317 - val_accuracy: 0.6885\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 39s 310ms/step - loss: 0.1874 - accuracy: 0.9076 - val_loss: 2.7423 - val_accuracy: 0.6922\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 39s 310ms/step - loss: 0.1879 - accuracy: 0.9087 - val_loss: 2.7325 - val_accuracy: 0.6884\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 39s 309ms/step - loss: 0.1873 - accuracy: 0.9086 - val_loss: 2.7249 - val_accuracy: 0.6883\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 39s 310ms/step - loss: 0.1883 - accuracy: 0.9079 - val_loss: 2.7343 - val_accuracy: 0.6890\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 39s 311ms/step - loss: 0.1872 - accuracy: 0.9086 - val_loss: 2.7389 - val_accuracy: 0.6896\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 39s 313ms/step - loss: 0.1874 - accuracy: 0.9082 - val_loss: 2.7330 - val_accuracy: 0.6902\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 39s 315ms/step - loss: 0.1860 - accuracy: 0.9081 - val_loss: 2.7400 - val_accuracy: 0.6888\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 39s 312ms/step - loss: 0.1856 - accuracy: 0.9080 - val_loss: 2.7486 - val_accuracy: 0.6887\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 39s 315ms/step - loss: 0.1858 - accuracy: 0.9074 - val_loss: 2.7268 - val_accuracy: 0.6880\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 39s 314ms/step - loss: 0.1842 - accuracy: 0.9095 - val_loss: 2.7439 - val_accuracy: 0.6905\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 40s 317ms/step - loss: 0.1860 - accuracy: 0.9069 - val_loss: 2.7623 - val_accuracy: 0.6907\n",
      "Epoch 167/200\n",
      "125/125 [==============================] - 39s 315ms/step - loss: 0.1860 - accuracy: 0.9077 - val_loss: 2.7525 - val_accuracy: 0.6887\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 39s 316ms/step - loss: 0.1867 - accuracy: 0.9079 - val_loss: 2.7370 - val_accuracy: 0.6896\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 40s 320ms/step - loss: 0.1840 - accuracy: 0.9093 - val_loss: 2.7527 - val_accuracy: 0.6914\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 39s 316ms/step - loss: 0.1841 - accuracy: 0.9082 - val_loss: 2.7608 - val_accuracy: 0.6887\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - 39s 316ms/step - loss: 0.1855 - accuracy: 0.9069 - val_loss: 2.7557 - val_accuracy: 0.6878\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 40s 320ms/step - loss: 0.1834 - accuracy: 0.9089 - val_loss: 2.7609 - val_accuracy: 0.6902\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 40s 319ms/step - loss: 0.1855 - accuracy: 0.9074 - val_loss: 2.7694 - val_accuracy: 0.6876\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 40s 323ms/step - loss: 0.1832 - accuracy: 0.9085 - val_loss: 2.7828 - val_accuracy: 0.6903\n",
      "Epoch 175/200\n",
      "125/125 [==============================] - 40s 319ms/step - loss: 0.1846 - accuracy: 0.9072 - val_loss: 2.7662 - val_accuracy: 0.6906\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - 40s 319ms/step - loss: 0.1833 - accuracy: 0.9078 - val_loss: 2.7669 - val_accuracy: 0.6913\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - 40s 321ms/step - loss: 0.1825 - accuracy: 0.9064 - val_loss: 2.7781 - val_accuracy: 0.6903\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - 40s 320ms/step - loss: 0.1814 - accuracy: 0.9089 - val_loss: 2.7852 - val_accuracy: 0.6907\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - 40s 319ms/step - loss: 0.1826 - accuracy: 0.9078 - val_loss: 2.7763 - val_accuracy: 0.6863\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - 40s 320ms/step - loss: 0.1815 - accuracy: 0.9084 - val_loss: 2.7682 - val_accuracy: 0.6908\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - 40s 322ms/step - loss: 0.1810 - accuracy: 0.9082 - val_loss: 2.7670 - val_accuracy: 0.6896\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - 40s 322ms/step - loss: 0.1797 - accuracy: 0.9087 - val_loss: 2.7822 - val_accuracy: 0.6901\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - 40s 321ms/step - loss: 0.1801 - accuracy: 0.9080 - val_loss: 2.7808 - val_accuracy: 0.6921\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - 40s 323ms/step - loss: 0.1805 - accuracy: 0.9088 - val_loss: 2.7765 - val_accuracy: 0.6916\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - 40s 322ms/step - loss: 0.1817 - accuracy: 0.9083 - val_loss: 2.7812 - val_accuracy: 0.6903\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - 40s 322ms/step - loss: 0.1788 - accuracy: 0.9089 - val_loss: 2.7833 - val_accuracy: 0.6908\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - 41s 325ms/step - loss: 0.1793 - accuracy: 0.9097 - val_loss: 2.7874 - val_accuracy: 0.6868\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - 40s 324ms/step - loss: 0.1801 - accuracy: 0.9081 - val_loss: 2.7782 - val_accuracy: 0.6895\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - 40s 323ms/step - loss: 0.1779 - accuracy: 0.9100 - val_loss: 2.7963 - val_accuracy: 0.6872\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - 41s 325ms/step - loss: 0.1792 - accuracy: 0.9093 - val_loss: 2.8024 - val_accuracy: 0.6884\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - 41s 326ms/step - loss: 0.1788 - accuracy: 0.9084 - val_loss: 2.8065 - val_accuracy: 0.6903\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - 41s 327ms/step - loss: 0.1769 - accuracy: 0.9099 - val_loss: 2.7958 - val_accuracy: 0.6884\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - 42s 333ms/step - loss: 0.1795 - accuracy: 0.9080 - val_loss: 2.8056 - val_accuracy: 0.6904\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - 43s 341ms/step - loss: 0.1796 - accuracy: 0.9081 - val_loss: 2.7904 - val_accuracy: 0.6901\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - 47s 376ms/step - loss: 0.1777 - accuracy: 0.9089 - val_loss: 2.7762 - val_accuracy: 0.6886\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - 47s 375ms/step - loss: 0.1780 - accuracy: 0.9092 - val_loss: 2.7875 - val_accuracy: 0.6892\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - 46s 369ms/step - loss: 0.1776 - accuracy: 0.9088 - val_loss: 2.8009 - val_accuracy: 0.6907\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - 46s 366ms/step - loss: 0.1788 - accuracy: 0.9082 - val_loss: 2.7910 - val_accuracy: 0.6895\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - 46s 365ms/step - loss: 0.1775 - accuracy: 0.9082 - val_loss: 2.7892 - val_accuracy: 0.6894\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - 46s 367ms/step - loss: 0.1755 - accuracy: 0.9094 - val_loss: 2.7988 - val_accuracy: 0.6887\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros((NUM_SAMPLES, LATENT_DIM_DECODER)) #initial [s,c]\n",
    "r = model.fit(\n",
    "    [encoder_inputs, decoder_inputs, z, z], decoder_targets,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs= EPOCHS,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b30ac77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c28f0e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['accuracy'], label='accuracy')\n",
    "plt.plot(r.history[\"val_accuracy\"], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbad603",
   "metadata": {},
   "source": [
    "# Encoder and Decoder Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "517b407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30901f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe8c7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = one_step_attention(encoder_outputs_as_input, initial_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3233535",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18019a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "o,s,c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o) #softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2bb46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    inputs=[\n",
    "        decoder_inputs_single,\n",
    "        encoder_outputs_as_input,\n",
    "        initial_s,\n",
    "        initial_c\n",
    "    ],\n",
    "    outputs=[decoder_outputs, s, c]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad1876de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real words\n",
    "idx2word_eng = {v:k for k,v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k,v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f2c1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_sequence(input_seq):\n",
    "    #encode the input as state vectors\n",
    "    enc_out = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #empty target for first sequence\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    target_seq[0,0] = word2idx_outputs['<sos>']\n",
    "    \n",
    "    #if we get the end break\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    \n",
    "    s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    \n",
    "    output_sentence = []\n",
    "    for _ in range(max_len_target):\n",
    "        #return output hidden state and cell state\n",
    "        o, s, c =decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        \n",
    "        idx = np.argmax(o.flatten())\n",
    "        \n",
    "        if eos == idx:\n",
    "            break\n",
    "            \n",
    "        word=''\n",
    "        if idx > 0:\n",
    "            word = idx2word_trans[idx]\n",
    "            output_sentence.append(word)\n",
    "            \n",
    "        target_seq[0,0] = idx\n",
    "        \n",
    "    return ' '.join(output_sentence)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62c92880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "_\n",
      "Input:  Go slow.\n",
      "Translation: vaya despacio.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "_\n",
      "Input:  I'm not bossy.\n",
      "Translation: no soy mandn.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "_\n",
      "Input:  What a night!\n",
      "Translation: qu noche!\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "_\n",
      "Input:  He scolded her.\n",
      "Translation: l la\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "_\n",
      "Input:  I just got up.\n",
      "Translation: recin me acabo levantar. levantar.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "_\n",
      "Input:  I'll be working.\n",
      "Translation: voy a\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "_\n",
      "Input:  Which key is it?\n",
      "Translation: cmo de pequeo es?\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "_\n",
      "Input:  Help is coming.\n",
      "Translation: la ayuda est llegando.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "_\n",
      "Input:  What's in there?\n",
      "Translation: qu hay ah.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "_\n",
      "Input:  Describe Tom.\n",
      "Translation: descrbalo a toms.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "_\n",
      "Input:  He gave in.\n",
      "Translation: l se rindi.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "_\n",
      "Input:  Wash your hands.\n",
      "Translation: lvate tus cara.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "_\n",
      "Input:  Am I dreaming?\n",
      "Translation: estoy soando?\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "_\n",
      "Input:  I am too short.\n",
      "Translation: soy demasiado bajo.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "_\n",
      "Input:  Don't be naive.\n",
      "Translation: no seas ingenuo.\n",
      "Continue? Y/n: y\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "_\n",
      "Input:  It's OK to cry.\n",
      "Translation: est bien llorar.\n",
      "Continue? Y/n: n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    i = np.random.choice(len(input_texts))\n",
    "    input_seq = encoder_inputs[i:i+1]\n",
    "    translation = decoder_sequence(input_seq)\n",
    "    print(\"_\")\n",
    "    print(\"Input: \", input_texts[i])\n",
    "    print(\"Translation:\", translation)\n",
    "    \n",
    "    ans = input(\"Continue? Y/n: \")\n",
    "    if ans and ans.lower().startswith('n'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b67eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
